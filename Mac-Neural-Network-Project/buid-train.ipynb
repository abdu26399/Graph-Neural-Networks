{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(\"numpy==\"+np.__version__)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(\"tensorflow==\"+tf.__version__)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"pandas==\"+pd.__version__)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(\"mlflow==\"+mlflow.__version__)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mt\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# print(\"numpy==\"+np.__version__)\n",
    "# print(\"tensorflow==\"+tf.__version__)\n",
    "# print(\"pandas==\"+pd.__version__)\n",
    "# print(\"mlflow==\"+mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=10\n",
    "epochs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Metal device set to: Apple M1 Pro\n",
      " Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 17:18:43.791220: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-20 17:18:43.791352: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/4', experiment_id='4', lifecycle_stage='active', name='graph-neural-network-trial-batch-norm', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"graph-neural-network-trial-batch-norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjm(h,w,near):\n",
    "#   am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "#   img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "#   dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "#   for i,v in enumerate(img):\n",
    "#     for j,v2 in enumerate(img[i]):\n",
    "#       timg=[[0 for i in range(w)] for j in range(h)]\n",
    "#       for k in range(0,near+1):\n",
    "#         for d in dr:\n",
    "#           posy=i+d[0]*k\n",
    "#           posx=j+d[1]*k\n",
    "#           if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "#             timg[posy][posx]=1\n",
    "#             am[i*w+j][posy*w+posx]=1\n",
    "#         print(timg)  \n",
    "\n",
    "#   return am\n",
    "\n",
    "# val=adjm(4,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train/x_train.pkl','rb') as f:\n",
    "        x1=pickle.load(f)\n",
    "with open('data/train/y_train.pkl','rb') as f:\n",
    "        y1=pickle.load( f)\n",
    "with open('data/valid/x_valid.pkl','rb') as f:\n",
    "        x2=pickle.load(f)\n",
    "with open('data/valid/y_valid.pkl','rb') as f:\n",
    "        y2=pickle.load( f)\n",
    "# with open('data/test/x_test.pkl','rb') as f:\n",
    "#         x3=pickle.load(f)\n",
    "# with open('data/test/y_test.pkl','rb') as f:\n",
    "#         y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test/x_test.pkl','rb') as f:\n",
    "        x3=pickle.load(f)\n",
    "with open('data/test/y_test.pkl','rb') as f:\n",
    "        y3=pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 9, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print(max(y1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,inp_shape=9*12,out_shape=9*12,h=9, w=12,near=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.am=[[0 for i in range(w*h)] for j in range(h*w)]\n",
    "        self.img=[[0 for i in range(w)] for j in range(h)]\n",
    "  \n",
    "        self.dr=[[1,0],[0,1],[1,1],[-1,-1],[-1,0],[0,-1],[-1,1],[1,-1]]\n",
    "\n",
    "        for i,v in enumerate(self.img):\n",
    "           for j,v2 in enumerate(self.img[i]):\n",
    "        # timg=[[0 for i in range(w)] for j in range(h)]\n",
    "              for k in range(0,near+1):\n",
    "                for d in self.dr:\n",
    "                  posy=i+d[0]*k\n",
    "                  posx=j+d[1]*k\n",
    "                  if posy>=0 and posy<h and posx>=0 and posx<w:\n",
    "            # timg[posy][posx]=1\n",
    "                    self.am[i*w+j][posy*w+posx]=1\n",
    "        # print(timg) \n",
    "        self.am=np.array(self.am) \n",
    "        self.D = np.diag(np.sum(self.am, axis=0)) \n",
    "        self.Dinv=np.linalg.inv(self.D)\n",
    "        self.am=tf.Variable(self.am,trainable=True,dtype=tf.float32)\n",
    "        self.Dinv=tf.Variable(self.Dinv,trainable=True,dtype=tf.float32)\n",
    "        # self.norm=tf.matmul(self.Dinv*self.am)\n",
    "        self.w = self.add_weight(\n",
    "            shape=(inp_shape, out_shape), initializer=\"random_normal\", trainable=True,dtype=tf.float32\n",
    "        )\n",
    "        # self.b = self.add_weight(shape=(units,), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs=tf.cast(inputs,dtype=tf.float32)\n",
    "    \n",
    "        # print(\"inpshape\",tf.transpose(inputs,perm=[1,0]).shape)\n",
    "        # print(self.Dinv.shape)\n",
    "        # print(self.am.shape)\n",
    "        # print(self.w.shape)\n",
    "        first_half=tf.matmul(inputs,tf.matmul(self.Dinv,self.am))\n",
    "    \n",
    "        return tf.matmul(first_half, self.w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(near=3,lay=2,bs=bs,n_out=7):\n",
    "    inputs = tf.keras.Input( shape=(9,12),\n",
    "    batch_size=bs)\n",
    "    mlflow.log_param(\"layers\", lay)\n",
    "    mlflow.log_param(\"nearest\", near)\n",
    "    mlflow.set_tag(\"layer\", \"changed\")\n",
    "    print(inputs.shape)\n",
    "    x=tf.reshape(inputs,[bs,inputs.shape[1]*inputs.shape[2]],name=\"initial reshape\")\n",
    "    for i in range(lay):\n",
    "        x=GCN(near=near)(x)\n",
    "        x=tf.keras.layers.Activation('relu',name=\"graph_layer\"+str(i+1))(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.Dense(units=32,activation=\"relu\",name=\"dense1\")(x)\n",
    "    output=tf.keras.layers.Dense(n_out,activation=\"softmax\",name=\"out_layer\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=\"graph_neuralnetwork\")\n",
    "\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9, 12)\n"
     ]
    }
   ],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"graph_neuralnetwork\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(10, 9, 12)]             0         \n",
      "                                                                 \n",
      " tf.reshape_1 (TFOpLambda)   (10, 108)                 0         \n",
      "                                                                 \n",
      " gcn_2 (GCN)                 (10, 108)                 34992     \n",
      "                                                                 \n",
      " graph_layer1 (Activation)   (10, 108)                 0         \n",
      "                                                                 \n",
      " gcn_3 (GCN)                 (10, 108)                 34992     \n",
      "                                                                 \n",
      " graph_layer2 (Activation)   (10, 108)                 0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (10, 108)                432       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense1 (Dense)              (10, 32)                  3488      \n",
      "                                                                 \n",
      " out_layer (Dense)           (10, 7)                   231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,135\n",
      "Trainable params: 73,919\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"mode/base_model\",\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer GCN has arguments ['self', 'inp_shape', 'out_shape', 'h', 'w', 'near']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/20 17:33:03 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Changing param values is not allowed. Param with key='opt_learning_rate' was already logged with value='0.0001' for run ID='bc8b4c4cf7f94116bd09b91367fb4031'. Attempted logging new value '0.01'.\n",
      "\n",
      "The cause of this error is typically due to repeated calls\n",
      "to an individual run_id event logging.\n",
      "\n",
      "Incorrect Example:\n",
      "---------------------------------------\n",
      "with mlflow.start_run():\n",
      "    mlflow.log_param(\"depth\", 3)\n",
      "    mlflow.log_param(\"depth\", 5)\n",
      "---------------------------------------\n",
      "\n",
      "Which will throw an MlflowException for overwriting a\n",
      "logged parameter.\n",
      "\n",
      "Correct Example:\n",
      "---------------------------------------\n",
      "with mlflow.start_run():\n",
      "    with mlflow.start_run(nested=True):\n",
      "        mlflow.log_param(\"depth\", 3)\n",
      "    with mlflow.start_run(nested=True):\n",
      "        mlflow.log_param(\"depth\", 5)\n",
      "---------------------------------------\n",
      "\n",
      "Which will create a new nested run for each individual\n",
      "model and prevent parameter key collisions within the\n",
      "tracking store.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 17:33:03.411341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 1s - loss: 2.1005 - accuracy: 0.1357 - val_loss: 7.3416 - val_accuracy: 0.1500 - 748ms/epoch - 18ms/step\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 17:33:03.897058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 0s - loss: 1.9110 - accuracy: 0.1690 - val_loss: 55.2584 - val_accuracy: 0.1929 - 421ms/epoch - 10ms/step\n",
      "Epoch 3/150\n",
      "42/42 - 0s - loss: 2.0709 - accuracy: 0.1881 - val_loss: 45.8470 - val_accuracy: 0.1429 - 424ms/epoch - 10ms/step\n",
      "Epoch 4/150\n",
      "42/42 - 0s - loss: 1.9398 - accuracy: 0.2214 - val_loss: 5.7503 - val_accuracy: 0.1357 - 406ms/epoch - 10ms/step\n",
      "Epoch 5/150\n",
      "42/42 - 0s - loss: 1.8807 - accuracy: 0.2024 - val_loss: 4.8632 - val_accuracy: 0.2214 - 403ms/epoch - 10ms/step\n",
      "Epoch 6/150\n",
      "42/42 - 0s - loss: 1.8779 - accuracy: 0.1976 - val_loss: 6.1984 - val_accuracy: 0.1429 - 408ms/epoch - 10ms/step\n",
      "Epoch 7/150\n",
      "42/42 - 0s - loss: 1.8221 - accuracy: 0.2333 - val_loss: 5.6577 - val_accuracy: 0.1429 - 399ms/epoch - 9ms/step\n",
      "Epoch 8/150\n",
      "42/42 - 0s - loss: 1.8137 - accuracy: 0.2429 - val_loss: 2.0452 - val_accuracy: 0.2214 - 401ms/epoch - 10ms/step\n",
      "Epoch 9/150\n",
      "42/42 - 0s - loss: 1.8076 - accuracy: 0.2548 - val_loss: 3.1856 - val_accuracy: 0.1500 - 414ms/epoch - 10ms/step\n",
      "Epoch 10/150\n",
      "42/42 - 0s - loss: 1.8233 - accuracy: 0.2119 - val_loss: 6.5792 - val_accuracy: 0.1500 - 406ms/epoch - 10ms/step\n",
      "Epoch 11/150\n",
      "42/42 - 0s - loss: 1.8409 - accuracy: 0.2095 - val_loss: 8.8441 - val_accuracy: 0.1429 - 413ms/epoch - 10ms/step\n",
      "Epoch 12/150\n",
      "42/42 - 0s - loss: 1.7820 - accuracy: 0.2429 - val_loss: 15.2058 - val_accuracy: 0.1429 - 426ms/epoch - 10ms/step\n",
      "Epoch 13/150\n",
      "42/42 - 0s - loss: 1.8242 - accuracy: 0.2452 - val_loss: 6.4877 - val_accuracy: 0.1429 - 423ms/epoch - 10ms/step\n",
      "Epoch 14/150\n",
      "42/42 - 0s - loss: 1.7546 - accuracy: 0.2595 - val_loss: 3.9441 - val_accuracy: 0.1500 - 402ms/epoch - 10ms/step\n",
      "Epoch 15/150\n",
      "42/42 - 0s - loss: 1.8448 - accuracy: 0.2429 - val_loss: 6.0596 - val_accuracy: 0.1357 - 405ms/epoch - 10ms/step\n",
      "Epoch 16/150\n",
      "42/42 - 0s - loss: 1.7827 - accuracy: 0.2643 - val_loss: 10.3511 - val_accuracy: 0.1571 - 406ms/epoch - 10ms/step\n",
      "Epoch 17/150\n",
      "42/42 - 0s - loss: 1.7560 - accuracy: 0.2857 - val_loss: 4.0064 - val_accuracy: 0.1429 - 404ms/epoch - 10ms/step\n",
      "Epoch 18/150\n",
      "42/42 - 0s - loss: 1.7617 - accuracy: 0.2786 - val_loss: 15.1396 - val_accuracy: 0.0786 - 455ms/epoch - 11ms/step\n",
      "Epoch 19/150\n",
      "42/42 - 0s - loss: 1.7407 - accuracy: 0.2833 - val_loss: 3.4214 - val_accuracy: 0.1429 - 400ms/epoch - 10ms/step\n",
      "Epoch 20/150\n",
      "42/42 - 0s - loss: 1.7085 - accuracy: 0.2881 - val_loss: 2.6132 - val_accuracy: 0.1929 - 418ms/epoch - 10ms/step\n",
      "Epoch 21/150\n",
      "42/42 - 0s - loss: 1.7219 - accuracy: 0.2881 - val_loss: 2.8162 - val_accuracy: 0.1643 - 419ms/epoch - 10ms/step\n",
      "Epoch 22/150\n",
      "42/42 - 0s - loss: 1.7566 - accuracy: 0.2595 - val_loss: 17.0235 - val_accuracy: 0.1429 - 403ms/epoch - 10ms/step\n",
      "Epoch 23/150\n",
      "42/42 - 0s - loss: 1.7250 - accuracy: 0.2786 - val_loss: 6.4268 - val_accuracy: 0.1571 - 404ms/epoch - 10ms/step\n",
      "Epoch 24/150\n",
      "42/42 - 0s - loss: 1.6524 - accuracy: 0.3286 - val_loss: 2.2695 - val_accuracy: 0.2429 - 402ms/epoch - 10ms/step\n",
      "Epoch 25/150\n",
      "42/42 - 0s - loss: 1.6551 - accuracy: 0.3000 - val_loss: 4.7876 - val_accuracy: 0.1429 - 400ms/epoch - 10ms/step\n",
      "Epoch 26/150\n",
      "42/42 - 0s - loss: 1.7428 - accuracy: 0.2976 - val_loss: 19.6660 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 27/150\n",
      "42/42 - 0s - loss: 1.6434 - accuracy: 0.2833 - val_loss: 2.2085 - val_accuracy: 0.1857 - 408ms/epoch - 10ms/step\n",
      "Epoch 28/150\n",
      "42/42 - 0s - loss: 1.6445 - accuracy: 0.3310 - val_loss: 3.6387 - val_accuracy: 0.1500 - 403ms/epoch - 10ms/step\n",
      "Epoch 29/150\n",
      "42/42 - 0s - loss: 1.6266 - accuracy: 0.3333 - val_loss: 8.9889 - val_accuracy: 0.1429 - 404ms/epoch - 10ms/step\n",
      "Epoch 30/150\n",
      "42/42 - 0s - loss: 1.6679 - accuracy: 0.3429 - val_loss: 5.6972 - val_accuracy: 0.1786 - 403ms/epoch - 10ms/step\n",
      "Epoch 31/150\n",
      "42/42 - 0s - loss: 1.6134 - accuracy: 0.3381 - val_loss: 2.1578 - val_accuracy: 0.2214 - 402ms/epoch - 10ms/step\n",
      "Epoch 32/150\n",
      "42/42 - 0s - loss: 1.6068 - accuracy: 0.3619 - val_loss: 1.9501 - val_accuracy: 0.2571 - 403ms/epoch - 10ms/step\n",
      "Epoch 33/150\n",
      "42/42 - 0s - loss: 1.5945 - accuracy: 0.3619 - val_loss: 5.4600 - val_accuracy: 0.1929 - 404ms/epoch - 10ms/step\n",
      "Epoch 34/150\n",
      "42/42 - 0s - loss: 1.7230 - accuracy: 0.2976 - val_loss: 6.5850 - val_accuracy: 0.1857 - 404ms/epoch - 10ms/step\n",
      "Epoch 35/150\n",
      "42/42 - 0s - loss: 1.7204 - accuracy: 0.3238 - val_loss: 4.9833 - val_accuracy: 0.2143 - 402ms/epoch - 10ms/step\n",
      "Epoch 36/150\n",
      "42/42 - 0s - loss: 1.6447 - accuracy: 0.3286 - val_loss: 2.1286 - val_accuracy: 0.2000 - 460ms/epoch - 11ms/step\n",
      "Epoch 37/150\n",
      "42/42 - 0s - loss: 1.6291 - accuracy: 0.2833 - val_loss: 2.2819 - val_accuracy: 0.2000 - 405ms/epoch - 10ms/step\n",
      "Epoch 38/150\n",
      "42/42 - 0s - loss: 1.6357 - accuracy: 0.3548 - val_loss: 7.6206 - val_accuracy: 0.1357 - 404ms/epoch - 10ms/step\n",
      "Epoch 39/150\n",
      "42/42 - 0s - loss: 1.6305 - accuracy: 0.3262 - val_loss: 3.1107 - val_accuracy: 0.2143 - 407ms/epoch - 10ms/step\n",
      "Epoch 40/150\n",
      "42/42 - 0s - loss: 1.6037 - accuracy: 0.3333 - val_loss: 3.2781 - val_accuracy: 0.1786 - 404ms/epoch - 10ms/step\n",
      "Epoch 41/150\n",
      "42/42 - 0s - loss: 1.5486 - accuracy: 0.3571 - val_loss: 2.1130 - val_accuracy: 0.2071 - 405ms/epoch - 10ms/step\n",
      "Epoch 42/150\n",
      "42/42 - 0s - loss: 1.6211 - accuracy: 0.3357 - val_loss: 4.3853 - val_accuracy: 0.1643 - 404ms/epoch - 10ms/step\n",
      "Epoch 43/150\n",
      "42/42 - 0s - loss: 1.7321 - accuracy: 0.2905 - val_loss: 9.4252 - val_accuracy: 0.1429 - 405ms/epoch - 10ms/step\n",
      "Epoch 44/150\n",
      "42/42 - 0s - loss: 1.5839 - accuracy: 0.3643 - val_loss: 2.2432 - val_accuracy: 0.2286 - 405ms/epoch - 10ms/step\n",
      "Epoch 45/150\n",
      "42/42 - 0s - loss: 1.5638 - accuracy: 0.3571 - val_loss: 2.8594 - val_accuracy: 0.2214 - 403ms/epoch - 10ms/step\n",
      "Epoch 46/150\n",
      "42/42 - 0s - loss: 1.5651 - accuracy: 0.3690 - val_loss: 2.2500 - val_accuracy: 0.2000 - 401ms/epoch - 10ms/step\n",
      "Epoch 47/150\n",
      "42/42 - 0s - loss: 1.6106 - accuracy: 0.3667 - val_loss: 8.5365 - val_accuracy: 0.1500 - 402ms/epoch - 10ms/step\n",
      "Epoch 48/150\n",
      "42/42 - 0s - loss: 1.5991 - accuracy: 0.3548 - val_loss: 10.0757 - val_accuracy: 0.1500 - 402ms/epoch - 10ms/step\n",
      "Epoch 49/150\n",
      "42/42 - 0s - loss: 1.6006 - accuracy: 0.3762 - val_loss: 13.8993 - val_accuracy: 0.1429 - 404ms/epoch - 10ms/step\n",
      "Epoch 50/150\n",
      "42/42 - 0s - loss: 1.6365 - accuracy: 0.3214 - val_loss: 8.6422 - val_accuracy: 0.1500 - 402ms/epoch - 10ms/step\n",
      "Epoch 51/150\n",
      "42/42 - 0s - loss: 1.5733 - accuracy: 0.3690 - val_loss: 2.4362 - val_accuracy: 0.2071 - 399ms/epoch - 10ms/step\n",
      "Epoch 52/150\n",
      "42/42 - 0s - loss: 1.5979 - accuracy: 0.3714 - val_loss: 6.3008 - val_accuracy: 0.1429 - 403ms/epoch - 10ms/step\n",
      "Epoch 53/150\n",
      "42/42 - 0s - loss: 1.5566 - accuracy: 0.3810 - val_loss: 6.4425 - val_accuracy: 0.1571 - 400ms/epoch - 10ms/step\n",
      "Epoch 54/150\n",
      "42/42 - 0s - loss: 1.5480 - accuracy: 0.3857 - val_loss: 4.4416 - val_accuracy: 0.1786 - 401ms/epoch - 10ms/step\n",
      "Epoch 55/150\n",
      "42/42 - 0s - loss: 1.6694 - accuracy: 0.3548 - val_loss: 12.4638 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 56/150\n",
      "42/42 - 0s - loss: 1.6891 - accuracy: 0.3095 - val_loss: 10.4544 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 57/150\n",
      "42/42 - 0s - loss: 1.7018 - accuracy: 0.2976 - val_loss: 4.2008 - val_accuracy: 0.2143 - 403ms/epoch - 10ms/step\n",
      "Epoch 58/150\n",
      "42/42 - 0s - loss: 1.6427 - accuracy: 0.3238 - val_loss: 17.1705 - val_accuracy: 0.1643 - 399ms/epoch - 10ms/step\n",
      "Epoch 59/150\n",
      "42/42 - 0s - loss: 1.6737 - accuracy: 0.3286 - val_loss: 4.3005 - val_accuracy: 0.1929 - 399ms/epoch - 10ms/step\n",
      "Epoch 60/150\n",
      "42/42 - 0s - loss: 1.6095 - accuracy: 0.3714 - val_loss: 2.1311 - val_accuracy: 0.2286 - 402ms/epoch - 10ms/step\n",
      "Epoch 61/150\n",
      "42/42 - 0s - loss: 1.5971 - accuracy: 0.3667 - val_loss: 3.3652 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 62/150\n",
      "42/42 - 0s - loss: 1.5580 - accuracy: 0.3905 - val_loss: 3.6543 - val_accuracy: 0.1571 - 404ms/epoch - 10ms/step\n",
      "Epoch 63/150\n",
      "42/42 - 0s - loss: 1.5414 - accuracy: 0.3905 - val_loss: 3.9307 - val_accuracy: 0.1857 - 402ms/epoch - 10ms/step\n",
      "Epoch 64/150\n",
      "42/42 - 0s - loss: 1.6192 - accuracy: 0.3595 - val_loss: 2.1360 - val_accuracy: 0.2000 - 404ms/epoch - 10ms/step\n",
      "Epoch 65/150\n",
      "42/42 - 0s - loss: 1.5566 - accuracy: 0.3833 - val_loss: 2.5660 - val_accuracy: 0.2071 - 403ms/epoch - 10ms/step\n",
      "Epoch 66/150\n",
      "42/42 - 0s - loss: 1.5735 - accuracy: 0.3738 - val_loss: 6.7036 - val_accuracy: 0.1500 - 401ms/epoch - 10ms/step\n",
      "Epoch 67/150\n",
      "42/42 - 0s - loss: 1.6085 - accuracy: 0.3452 - val_loss: 29.3585 - val_accuracy: 0.1429 - 406ms/epoch - 10ms/step\n",
      "Epoch 68/150\n",
      "42/42 - 0s - loss: 1.7209 - accuracy: 0.2857 - val_loss: 12.2465 - val_accuracy: 0.1429 - 403ms/epoch - 10ms/step\n",
      "Epoch 69/150\n",
      "42/42 - 0s - loss: 1.6638 - accuracy: 0.2810 - val_loss: 2.9288 - val_accuracy: 0.1571 - 405ms/epoch - 10ms/step\n",
      "Epoch 70/150\n",
      "42/42 - 0s - loss: 1.6986 - accuracy: 0.3024 - val_loss: 14.2928 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 71/150\n",
      "42/42 - 0s - loss: 1.6234 - accuracy: 0.3310 - val_loss: 2.8632 - val_accuracy: 0.2143 - 402ms/epoch - 10ms/step\n",
      "Epoch 72/150\n",
      "42/42 - 0s - loss: 1.6741 - accuracy: 0.3286 - val_loss: 13.7123 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 73/150\n",
      "42/42 - 0s - loss: 1.5957 - accuracy: 0.3429 - val_loss: 6.7029 - val_accuracy: 0.1286 - 404ms/epoch - 10ms/step\n",
      "Epoch 74/150\n",
      "42/42 - 0s - loss: 1.5820 - accuracy: 0.3690 - val_loss: 5.7543 - val_accuracy: 0.1500 - 402ms/epoch - 10ms/step\n",
      "Epoch 75/150\n",
      "42/42 - 0s - loss: 1.5874 - accuracy: 0.3500 - val_loss: 3.8646 - val_accuracy: 0.1429 - 404ms/epoch - 10ms/step\n",
      "Epoch 76/150\n",
      "42/42 - 0s - loss: 1.4915 - accuracy: 0.4333 - val_loss: 4.9738 - val_accuracy: 0.2071 - 453ms/epoch - 11ms/step\n",
      "Epoch 77/150\n",
      "42/42 - 0s - loss: 1.5462 - accuracy: 0.3833 - val_loss: 6.1865 - val_accuracy: 0.1571 - 417ms/epoch - 10ms/step\n",
      "Epoch 78/150\n",
      "42/42 - 0s - loss: 1.5576 - accuracy: 0.3905 - val_loss: 2.8520 - val_accuracy: 0.1500 - 422ms/epoch - 10ms/step\n",
      "Epoch 79/150\n",
      "42/42 - 0s - loss: 1.5077 - accuracy: 0.3881 - val_loss: 2.9169 - val_accuracy: 0.2143 - 456ms/epoch - 11ms/step\n",
      "Epoch 80/150\n",
      "42/42 - 0s - loss: 1.5328 - accuracy: 0.4024 - val_loss: 2.8021 - val_accuracy: 0.1500 - 499ms/epoch - 12ms/step\n",
      "Epoch 81/150\n",
      "42/42 - 0s - loss: 1.5753 - accuracy: 0.3690 - val_loss: 5.7218 - val_accuracy: 0.1571 - 448ms/epoch - 11ms/step\n",
      "Epoch 82/150\n",
      "42/42 - 0s - loss: 1.5550 - accuracy: 0.3905 - val_loss: 4.9158 - val_accuracy: 0.1714 - 421ms/epoch - 10ms/step\n",
      "Epoch 83/150\n",
      "42/42 - 0s - loss: 1.5451 - accuracy: 0.3952 - val_loss: 11.5706 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 84/150\n",
      "42/42 - 0s - loss: 1.5457 - accuracy: 0.3762 - val_loss: 4.0190 - val_accuracy: 0.1786 - 403ms/epoch - 10ms/step\n",
      "Epoch 85/150\n",
      "42/42 - 0s - loss: 1.5549 - accuracy: 0.3857 - val_loss: 3.4594 - val_accuracy: 0.2071 - 405ms/epoch - 10ms/step\n",
      "Epoch 86/150\n",
      "42/42 - 0s - loss: 1.4802 - accuracy: 0.4476 - val_loss: 5.4000 - val_accuracy: 0.1429 - 467ms/epoch - 11ms/step\n",
      "Epoch 87/150\n",
      "42/42 - 0s - loss: 1.5041 - accuracy: 0.4310 - val_loss: 8.9529 - val_accuracy: 0.1429 - 423ms/epoch - 10ms/step\n",
      "Epoch 88/150\n",
      "42/42 - 0s - loss: 1.5196 - accuracy: 0.3762 - val_loss: 2.5471 - val_accuracy: 0.2357 - 401ms/epoch - 10ms/step\n",
      "Epoch 89/150\n",
      "42/42 - 0s - loss: 1.4664 - accuracy: 0.4000 - val_loss: 5.4640 - val_accuracy: 0.2071 - 406ms/epoch - 10ms/step\n",
      "Epoch 90/150\n",
      "42/42 - 0s - loss: 1.5224 - accuracy: 0.3976 - val_loss: 5.9834 - val_accuracy: 0.1857 - 410ms/epoch - 10ms/step\n",
      "Epoch 91/150\n",
      "42/42 - 0s - loss: 1.5458 - accuracy: 0.3810 - val_loss: 2.8494 - val_accuracy: 0.1500 - 408ms/epoch - 10ms/step\n",
      "Epoch 92/150\n",
      "42/42 - 0s - loss: 1.5800 - accuracy: 0.3548 - val_loss: 2.9101 - val_accuracy: 0.2286 - 421ms/epoch - 10ms/step\n",
      "Epoch 93/150\n",
      "42/42 - 0s - loss: 1.5598 - accuracy: 0.3619 - val_loss: 4.4047 - val_accuracy: 0.2286 - 412ms/epoch - 10ms/step\n",
      "Epoch 94/150\n",
      "42/42 - 0s - loss: 1.5201 - accuracy: 0.4214 - val_loss: 6.4160 - val_accuracy: 0.1857 - 416ms/epoch - 10ms/step\n",
      "Epoch 95/150\n",
      "42/42 - 0s - loss: 1.4970 - accuracy: 0.4262 - val_loss: 4.1121 - val_accuracy: 0.2143 - 405ms/epoch - 10ms/step\n",
      "Epoch 96/150\n",
      "42/42 - 0s - loss: 1.5783 - accuracy: 0.3810 - val_loss: 27.4677 - val_accuracy: 0.1429 - 435ms/epoch - 10ms/step\n",
      "Epoch 97/150\n",
      "42/42 - 0s - loss: 1.6814 - accuracy: 0.3286 - val_loss: 11.0144 - val_accuracy: 0.1500 - 434ms/epoch - 10ms/step\n",
      "Epoch 98/150\n",
      "42/42 - 0s - loss: 1.7457 - accuracy: 0.2810 - val_loss: 9.7641 - val_accuracy: 0.1500 - 410ms/epoch - 10ms/step\n",
      "Epoch 99/150\n",
      "42/42 - 0s - loss: 1.6091 - accuracy: 0.3738 - val_loss: 3.6595 - val_accuracy: 0.2214 - 404ms/epoch - 10ms/step\n",
      "Epoch 100/150\n",
      "42/42 - 0s - loss: 1.5549 - accuracy: 0.3929 - val_loss: 13.9100 - val_accuracy: 0.1429 - 400ms/epoch - 10ms/step\n",
      "Epoch 101/150\n",
      "42/42 - 0s - loss: 1.7142 - accuracy: 0.3381 - val_loss: 2.7631 - val_accuracy: 0.1429 - 405ms/epoch - 10ms/step\n",
      "Epoch 102/150\n",
      "42/42 - 0s - loss: 1.5591 - accuracy: 0.3690 - val_loss: 2.3672 - val_accuracy: 0.2143 - 453ms/epoch - 11ms/step\n",
      "Epoch 103/150\n",
      "42/42 - 0s - loss: 1.5304 - accuracy: 0.3786 - val_loss: 2.7300 - val_accuracy: 0.1357 - 409ms/epoch - 10ms/step\n",
      "Epoch 104/150\n",
      "42/42 - 0s - loss: 1.5479 - accuracy: 0.3738 - val_loss: 3.6562 - val_accuracy: 0.1429 - 422ms/epoch - 10ms/step\n",
      "Epoch 105/150\n",
      "42/42 - 0s - loss: 1.6679 - accuracy: 0.3214 - val_loss: 11.3863 - val_accuracy: 0.1429 - 411ms/epoch - 10ms/step\n",
      "Epoch 106/150\n",
      "42/42 - 0s - loss: 1.6591 - accuracy: 0.3381 - val_loss: 5.8243 - val_accuracy: 0.1429 - 409ms/epoch - 10ms/step\n",
      "Epoch 107/150\n",
      "42/42 - 0s - loss: 1.6616 - accuracy: 0.3000 - val_loss: 17.0779 - val_accuracy: 0.1429 - 419ms/epoch - 10ms/step\n",
      "Epoch 108/150\n",
      "42/42 - 0s - loss: 1.6943 - accuracy: 0.2786 - val_loss: 6.9642 - val_accuracy: 0.1429 - 421ms/epoch - 10ms/step\n",
      "Epoch 109/150\n",
      "42/42 - 0s - loss: 1.7145 - accuracy: 0.3167 - val_loss: 62.5252 - val_accuracy: 0.1429 - 406ms/epoch - 10ms/step\n",
      "Epoch 110/150\n",
      "42/42 - 0s - loss: 1.8241 - accuracy: 0.2452 - val_loss: 40.3866 - val_accuracy: 0.1429 - 430ms/epoch - 10ms/step\n",
      "Epoch 111/150\n",
      "42/42 - 0s - loss: 1.7725 - accuracy: 0.2762 - val_loss: 37.3671 - val_accuracy: 0.1429 - 426ms/epoch - 10ms/step\n",
      "Epoch 112/150\n",
      "42/42 - 0s - loss: 1.8868 - accuracy: 0.2143 - val_loss: 5.0917 - val_accuracy: 0.1286 - 410ms/epoch - 10ms/step\n",
      "Epoch 113/150\n",
      "42/42 - 0s - loss: 1.8053 - accuracy: 0.2190 - val_loss: 3.0603 - val_accuracy: 0.1500 - 431ms/epoch - 10ms/step\n",
      "Epoch 114/150\n",
      "42/42 - 0s - loss: 1.7288 - accuracy: 0.2810 - val_loss: 7.3144 - val_accuracy: 0.1643 - 413ms/epoch - 10ms/step\n",
      "Epoch 115/150\n",
      "42/42 - 0s - loss: 1.6611 - accuracy: 0.2857 - val_loss: 9.2041 - val_accuracy: 0.1214 - 403ms/epoch - 10ms/step\n",
      "Epoch 116/150\n",
      "42/42 - 0s - loss: 1.7060 - accuracy: 0.2905 - val_loss: 4.6195 - val_accuracy: 0.1429 - 401ms/epoch - 10ms/step\n",
      "Epoch 117/150\n",
      "42/42 - 0s - loss: 1.6776 - accuracy: 0.3024 - val_loss: 2.8742 - val_accuracy: 0.1643 - 441ms/epoch - 10ms/step\n",
      "Epoch 118/150\n",
      "42/42 - 0s - loss: 1.6527 - accuracy: 0.3190 - val_loss: 3.0756 - val_accuracy: 0.1643 - 417ms/epoch - 10ms/step\n",
      "Epoch 119/150\n",
      "42/42 - 0s - loss: 1.6866 - accuracy: 0.3143 - val_loss: 2.0132 - val_accuracy: 0.1786 - 409ms/epoch - 10ms/step\n",
      "Epoch 120/150\n",
      "42/42 - 0s - loss: 1.7280 - accuracy: 0.2738 - val_loss: 9.4245 - val_accuracy: 0.1143 - 402ms/epoch - 10ms/step\n",
      "Epoch 121/150\n",
      "42/42 - 0s - loss: 1.6802 - accuracy: 0.3095 - val_loss: 2.2960 - val_accuracy: 0.1500 - 397ms/epoch - 9ms/step\n",
      "Epoch 122/150\n",
      "42/42 - 0s - loss: 1.6701 - accuracy: 0.2881 - val_loss: 8.1977 - val_accuracy: 0.1500 - 405ms/epoch - 10ms/step\n",
      "Epoch 123/150\n",
      "42/42 - 0s - loss: 1.6819 - accuracy: 0.3190 - val_loss: 3.2647 - val_accuracy: 0.1643 - 420ms/epoch - 10ms/step\n",
      "Epoch 124/150\n",
      "42/42 - 0s - loss: 1.6284 - accuracy: 0.3286 - val_loss: 2.0762 - val_accuracy: 0.2143 - 402ms/epoch - 10ms/step\n",
      "Epoch 125/150\n",
      "42/42 - 0s - loss: 1.6052 - accuracy: 0.3357 - val_loss: 3.8113 - val_accuracy: 0.1357 - 402ms/epoch - 10ms/step\n",
      "Epoch 126/150\n",
      "42/42 - 0s - loss: 1.6266 - accuracy: 0.3095 - val_loss: 3.4622 - val_accuracy: 0.1286 - 403ms/epoch - 10ms/step\n",
      "Epoch 127/150\n",
      "42/42 - 0s - loss: 1.6393 - accuracy: 0.3143 - val_loss: 2.1402 - val_accuracy: 0.2286 - 453ms/epoch - 11ms/step\n",
      "Epoch 128/150\n",
      "42/42 - 0s - loss: 1.6161 - accuracy: 0.3119 - val_loss: 5.1282 - val_accuracy: 0.0929 - 404ms/epoch - 10ms/step\n",
      "Epoch 129/150\n",
      "42/42 - 0s - loss: 1.6211 - accuracy: 0.3643 - val_loss: 3.5896 - val_accuracy: 0.1214 - 407ms/epoch - 10ms/step\n",
      "Epoch 130/150\n",
      "42/42 - 0s - loss: 1.5660 - accuracy: 0.3571 - val_loss: 5.3844 - val_accuracy: 0.1500 - 419ms/epoch - 10ms/step\n",
      "Epoch 131/150\n",
      "42/42 - 0s - loss: 1.5988 - accuracy: 0.3333 - val_loss: 3.8928 - val_accuracy: 0.1071 - 404ms/epoch - 10ms/step\n",
      "Epoch 132/150\n",
      "42/42 - 0s - loss: 1.6149 - accuracy: 0.3238 - val_loss: 3.1516 - val_accuracy: 0.1571 - 424ms/epoch - 10ms/step\n",
      "Epoch 133/150\n",
      "42/42 - 0s - loss: 1.6382 - accuracy: 0.3000 - val_loss: 1.9158 - val_accuracy: 0.2786 - 413ms/epoch - 10ms/step\n",
      "Epoch 134/150\n",
      "42/42 - 0s - loss: 1.6397 - accuracy: 0.3357 - val_loss: 2.6375 - val_accuracy: 0.1571 - 413ms/epoch - 10ms/step\n",
      "Epoch 135/150\n",
      "42/42 - 0s - loss: 1.6099 - accuracy: 0.3262 - val_loss: 3.4461 - val_accuracy: 0.1429 - 419ms/epoch - 10ms/step\n",
      "Epoch 136/150\n",
      "42/42 - 0s - loss: 1.5887 - accuracy: 0.3476 - val_loss: 2.1981 - val_accuracy: 0.2857 - 401ms/epoch - 10ms/step\n",
      "Epoch 137/150\n",
      "42/42 - 0s - loss: 1.5787 - accuracy: 0.3476 - val_loss: 3.7769 - val_accuracy: 0.1286 - 411ms/epoch - 10ms/step\n",
      "Epoch 138/150\n",
      "42/42 - 0s - loss: 1.5775 - accuracy: 0.3357 - val_loss: 6.2016 - val_accuracy: 0.1786 - 435ms/epoch - 10ms/step\n",
      "Epoch 139/150\n",
      "42/42 - 0s - loss: 1.6221 - accuracy: 0.3262 - val_loss: 6.6303 - val_accuracy: 0.1929 - 402ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/20 17:34:01 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'NoneType' object has no attribute 'replace'\n"
     ]
    }
   ],
   "source": [
    "# with mlflow.start_run(nested=true):\n",
    "history = model.fit(x1,y1, batch_size=bs, epochs=epochs, callbacks=[callback],validation_data=(x2,y2),verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.functional.Functional"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ccd6447379f5e6f7b170904fd40d7e61f0af72b45d9bab3c3472de833a965dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
